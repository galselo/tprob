{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "from glob import glob\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = \"white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file where to load data (ERA5 Copernicus)\n",
    "fname_dataset = \"tn_ens_mean_0.1deg_reg_v23.1e.nc\"\n",
    "# minimum population number to add comuni (Italian NUTS-3 levels)\n",
    "pop_limit = 5e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4681db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "f = Dataset(fname_dataset)\n",
    "\n",
    "# strip times, latitude, and longitude \n",
    "times = f[\"time\"][:]\n",
    "lats = f[\"latitude\"][:]\n",
    "lons = f[\"longitude\"][:]\n",
    "\n",
    "# define lat lon range for Italy\n",
    "idx1 = (35 < lats) & (lats < 47)\n",
    "idx2 = (6 < lons) & (lons < 20)\n",
    "\n",
    "lats = lats[idx1]\n",
    "lons = lons[idx2]\n",
    "\n",
    "# strip lat/lon range (NOTE: it takes a while!)\n",
    "tn = f[\"tn\"][:, idx1, idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea96df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare geographical data (merge json NUTS-3 levels data)\n",
    "with open('italy_geo.json') as f:\n",
    "    geo_ref = json.load(f)\n",
    "\n",
    "with open('italy_cities.json') as f:\n",
    "    geo_more = json.load(f)\n",
    "\n",
    "geo = []\n",
    "for g in geo_ref:\n",
    "    if \"lat\" not in g:\n",
    "        continue\n",
    "    if \"\" in [g[\"lat\"], g[\"lng\"]]:\n",
    "        continue\n",
    "    for gm in geo_more:\n",
    "        if g[\"istat\"] == gm[\"istat\"]:\n",
    "            if float(gm[\"num_residenti\"]) >= pop_limit:\n",
    "                geo.append({**g, **gm})\n",
    "            break\n",
    "# sort alphabetically\n",
    "geo = sorted(geo, key=lambda x:x[\"comune\"])\n",
    "print(\"found %d city with more than %d population\" % (len(geo), pop_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d09afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(ymin, ymax, mmm):\n",
    "    # database starts from 1950\n",
    "    start_date = datetime.strptime(\"1/1/1950\", \"%d/%m/%Y\")\n",
    "\n",
    "    # define time range considering seasons\n",
    "    t_range = np.zeros_like(times, dtype=bool)\n",
    "    for y in range(ymin, ymax):\n",
    "        if mmm == \"djf\":\n",
    "            min_date = datetime.strptime(\"1/12/%d\" % (y-1), \"%d/%m/%Y\")\n",
    "            max_date = datetime.strptime(\"28/2/%d\" % y, \"%d/%m/%Y\")\n",
    "        elif mmm == \"mam\":\n",
    "            min_date = datetime.strptime(\"1/3/%d\" % y, \"%d/%m/%Y\")\n",
    "            max_date = datetime.strptime(\"31/5/%d\" % y, \"%d/%m/%Y\")\n",
    "        elif mmm == \"jja\":\n",
    "            min_date = datetime.strptime(\"1/4/%d\" % y, \"%d/%m/%Y\")\n",
    "            max_date = datetime.strptime(\"31/8/%d\" % y, \"%d/%m/%Y\")\n",
    "        elif mmm == \"son\":\n",
    "            min_date = datetime.strptime(\"1/9/%d\" % y, \"%d/%m/%Y\")\n",
    "            max_date = datetime.strptime(\"30/11/%d\" % y, \"%d/%m/%Y\")\n",
    "        else:\n",
    "            sys.exit(\"ERROR: season %s not found!\" % mmm)\n",
    "\n",
    "        # define time range index\n",
    "        tmin = (min_date - start_date).days\n",
    "        tmax = (max_date - start_date).days\n",
    "        \n",
    "        t_range[tmin:tmax] = True\n",
    "\n",
    "    # strip time range\n",
    "    return tn[t_range, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfeab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def do_statistics(tn_decade, lats, lons, geo):\n",
    "    stats = []\n",
    "    # loop on NUTS-3\n",
    "    for g in tqdm(geo):\n",
    "        gname, glat, glon = g[\"comune\"], float(g[\"lat\"]), float(g[\"lng\"])\n",
    "\n",
    "        # get lat lon corresponding indexes\n",
    "        i1 = np.argmin(np.abs(lats - glat))\n",
    "        i2 = np.argmin(np.abs(lons - glon))\n",
    "        found_ok = False\n",
    "        # loop around the cells to avoid empty data (i.e. outside the coastline)\n",
    "        for k in range(0, 10):\n",
    "            for i in range(-k, k+1):\n",
    "                for j in range(-k, k+1):\n",
    "                    tn_data = tn_decade[:, i1+i, i2+j].compressed()\n",
    "                    if len(tn_data) != 0:\n",
    "                        if tn_data.min() > -100:\n",
    "                            found_ok = True\n",
    "                            break\n",
    "                if found_ok:\n",
    "                    break\n",
    "            if found_ok:\n",
    "                break\n",
    "        if not found_ok:\n",
    "            print(\"ERROR: %s not found\" % gname)\n",
    "            continue\n",
    "        \n",
    "        # do statistical analysis (histogram and KDE)\n",
    "        bins = np.linspace(tn_data.min(), tn_data.max(), 100)\n",
    "        h, b = np.histogram(tn_data, bins=bins, density=True)\n",
    "        b = (b[1:] + b[:-1]) / 2.\n",
    "        kernel = gaussian_kde(tn_data)\n",
    "        y = kernel(b) / np.trapz(kernel(b), b)\n",
    "        \n",
    "        # get percentiles\n",
    "        xp = np.percentile(tn_data, [5, 25, 50, 75, 95])\n",
    "\n",
    "        # this is to plot for debugging\n",
    "        #print(tn_data.min(), tn_data.max())\n",
    "        #print(b)\n",
    "        #print(tn_data)\n",
    "        #print(np.isfinite(tn_data).all())\n",
    "        #print(np.isnan(tn_data).any())\n",
    "        #plt.plot(b, h)\n",
    "        #plt.plot(b, kernel(b))\n",
    "        #plt.title(gname)\n",
    "        #plt.show()\n",
    "        \n",
    "        # append results to the data stats structure\n",
    "        stats.append({\"name\": gname, \"xbin_min\": b.min(), \"xbin_max\": b.max(), \"kde\": list(y),\n",
    "                     \"xp\": list(xp)})\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save statistics to file\n",
    "def save_stats(stats, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(stats, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a803f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop on years and season to produce data (it might take a while)\n",
    "for ymin in [1950, 1960, 1980, 2000]:\n",
    "    ymax = ymin + 21\n",
    "    if ymin == 1950:\n",
    "        ymax = 2021\n",
    "    for mmm in [\"djf\", \"mam\", \"jja\", \"son\"]:\n",
    "        fname = 'results/%s_%d_%d.json' % (mmm, ymin, ymax)\n",
    "        tn_decade = select_data(ymin, ymax, mmm)\n",
    "        stats = do_statistics(tn_decade, lats, lons, geo)\n",
    "        save_stats(stats, fname)\n",
    "        print(\"%s saved\" % fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e96752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to write in individual NUTS-3 files, better for web application (smaller files)\n",
    "data = dict()\n",
    "for g in glob(\"results/*.json\"):\n",
    "    with open(g) as f:\n",
    "        data[g] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store into individual files for web application, one for NUTS-3 level\n",
    "comuni = []\n",
    "for i, g in enumerate(tqdm(geo)):\n",
    "\n",
    "    gname = g[\"comune\"]\n",
    "    comuni.append({\"name\": gname, \"lat\": float(g[\"lat\"]), \"lon\": float(g[\"lng\"])})\n",
    "    gd = dict()\n",
    "    for fname, d in data.items():\n",
    "        k = fname.replace(\"results/\", \"\").replace(\".json\", \"\")\n",
    "        gd[k] = d[i]\n",
    "        if d[i][\"name\"] != gname:\n",
    "            sys.exit(\"ERROR!\")\n",
    "    fname = \"results_web/data_%06d.json\" % i\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(gd, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec577e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save NUTS-3 levels to file, for web application\n",
    "with open(\"comuni.json\", 'w') as f:\n",
    "    json.dump(comuni, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae52e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
